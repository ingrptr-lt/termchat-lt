# ============================================================
#  TERMOS LT: SYSTEM CONFIGURATION TEMPLATE
# ============================================================
# INSTRUCTIONS:
# 1. Copy this file to a new file named '.env' (no extension)
# 2. Fill in your actual API keys in the .env file
# 3. DO NOT commit the real .env file to GitHub
# ============================================================

# --- 1. NEURAL NETWORK (AI) CONFIGURATION ---

# Primary AI Provider (options: openai, groq, zhipu)
# The system will prioritize keys for the selected provider.
AI_PROVIDER=groq

# API Keys (Required for AI features)
# Get one from: https://console.groq.com/ (Recommended for speed/cost)
OPENAI_API_KEY=sk-your-openai-key-here
GROQ_API_KEY=gsk-your-groq-key-here
ZHIPU_API_KEY=your-zhipu-api-key-here

# Default Model (e.g., llama3-8b-8192, gpt-4o, glm-4)
AI_MODEL=llama3-8b-8192

# --- 2. SERVER CONFIGURATION ---

# Port for the Backend Server (Python/Streamlit)
PORT=10000

# Host binding (0.0.0.0 = accessible from network, 127.0.0.1 = local only)
HOST=0.0.0.0

# --- 3. MQTT BROKER CONFIGURATION ---
# Used for Real-time Chat and Plugin System

MQTT_BROKER=broker.emqx.io
MQTT_PORT=8084
MQTT_TOPIC=termos/v3/chat
MQTT_USERNAME=
MQTT_PASSWORD=

# --- 4. SYSTEM FLAGS ---

# Enable Debug Mode (Shows detailed error logs)
DEBUG_MODE=False

# Enable Plugin System (Allows Python backend to execute docker plugins)
ENABLE_PLUGINS=True
